version: '3.2'
services:

  minio:
    container_name: minio
    image: minio/minio:RELEASE.2022-11-08T05-27-07Z
    command: server /data --console-address ":9001"
    ports:
      - "9001:9000"
      - "9002:9001"

  zookeeper:
    container_name: zookeeper
    image: wurstmeister/zookeeper:latest
    ports:
      - "2181:2181"

  course-kafka:
    container_name: course-kafka
    image: wurstmeister/kafka:2.13-2.8.1
    ports:
      - "29092:29092"
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://course-kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
      KAFKA_LOG_RETENTION_HOURS: 6
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    depends_on:
      - zookeeper

  kafdrop:
    container_name: kafdrop
    image: obsidiandynamics/kafdrop:3.30.0
    ports:
      - "9003:9000"
    environment:
      - KAFKA_BROKERCONNECT=course-kafka:9092
    depends_on:
      - course-kafka

  mariadb:
    container_name: mariadb
    image: mariadb:10.6
    ports:
      - "3306:3306"
    environment:
      MYSQL_ROOT_PASSWORD: admin
      MYSQL_USER: admin
      MYSQL_PASSWORD: admin
      MYSQL_DATABASE: metastore_db

  hive-metastore:
    container_name: hive_metastore
    image: ofrir119/hive-metastore:1.0
    ports:
      - "9083:9083"
    depends_on:
      - mariadb

  dev_env:
    container_name: dev_env
    image: ofrir119/developer_env:spark340_ssh
    ports:
      - "22022:22"
      - "8888:8888"
      - "4040:4040"
      - "4041:4041"
      - "4042:4042"
    environment:
      - SPARK_CLASSPATH=/opt/airflow/jars/postgresql-42.7.5.jar
    volumes:
      - ./jars:/opt/airflow/jars
      - ./archivePostgres:/opt/airflow

  mongo:
    container_name: mongo
    image: nayacollege/mongo:1.0
    ports:
      - "27017:27017"

  nifi:
    container_name: nifi
    image: nayacollege/nifi:1.0
    ports:
      - "8080:8080"

  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
    ports:
      - "9200:9200"
    environment:
      discovery.type: single-node

  kibana:
    container_name: kibana
    image: docker.elastic.co/kibana/kibana:7.13.2
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch

  postgres:
    container_name: postgres
    image: postgres:12
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=airflow
      - POSTGRES_PORT=5432

  airflow-init:
    container_name: airflow_init
    build:
      context: .
      dockerfile: Dockerfile.airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
    depends_on:
      - postgres
    entrypoint: /bin/bash
    command:
      - -c
      - >
        airflow users list || (
        airflow db init &&
        airflow users create
        --role Admin
        --username airflow
        --password airflow
        --email airflow@airflow.com
        --firstname airflow
        --lastname airflow )
    restart: on-failure

  airflow-webserver:
    container_name: airflow_webserver
    build:
      context: .
      dockerfile: Dockerfile.airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
    ports:
      - "8082:8080"
    command: airflow webserver
    depends_on:
      - postgres
    restart: always

  airflow-scheduler:
    container_name: airflow_scheduler
    build:
      context: .
      dockerfile: Dockerfile.airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    volumes:
      - ./dags:/opt/airflow/dags
      - ./airflow-data/logs:/opt/airflow/logs
      - ./airflow-data/plugins:/opt/airflow/plugins
      - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
    depends_on:
      - postgres
    command: airflow scheduler
    restart: always

  trino:
    container_name: trino
    image: ofrir119/trino:420
    ports:
      - "8080:8080"
    depends_on:
      - hive-metastore

networks:
  default:
    name: final_project_network





#     version: '3.2'
# services:

#   minio:
#     container_name: minio
#     image: minio/minio:RELEASE.2022-11-08T05-27-07Z
#     command: server /data --console-address ":9001"
#     ports:
#       - "9001:9000"
#       - "9002:9001"

#   zookeeper:
#     container_name: zookeeper
#     image: wurstmeister/zookeeper:latest
#     ports:
#       - "2181:2181"

#   course-kafka:
#     container_name: course-kafka
#     image: wurstmeister/kafka:2.13-2.8.1
#     ports:
#       - "29092:29092"
#     environment:
#       KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
#       KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
#       KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://course-kafka:9092,PLAINTEXT_HOST://localhost:29092
#       KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092
#       KAFKA_LOG_RETENTION_HOURS: 6
#       KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
#     depends_on:
#       - zookeeper
#     networks:
#       - default

#   kafdrop:
#     container_name: kafdrop
#     image: obsidiandynamics/kafdrop:3.30.0
#     ports:
#       - "9003:9000"
#     environment:
#       - KAFKA_BROKERCONNECT=course-kafka:9092
#     depends_on:
#       - course-kafka
#     networks:
#       - default

#   mariadb:
#     container_name: mariadb
#     image: mariadb:10.6
#     ports:
#       - "3306:3306"
#     environment:
#       MYSQL_ROOT_PASSWORD: admin
#       MYSQL_USER: admin
#       MYSQL_PASSWORD: admin
#       MYSQL_DATABASE: metastore_db
#     networks:
#       - default

#   hive-metastore:
#     container_name: hive_metastore
#     image: ofrir119/hive-metastore:1.0
#     ports:
#       - "9083:9083"
#     depends_on:
#       - mariadb
#     networks:
#       - default

#   dev_env:
#     container_name: dev_env
#     image: ofrir119/developer_env:spark340_ssh
#     ports:
#       - "22022:22"
#       - "8888:8888"
#       - "4040:4040"
#       - "4041:4041"
#       - "4042:4042"
#     environment:
#       - SPARK_CLASSPATH=/opt/airflow/jars/postgresql-42.7.5.jar
#     volumes:
#       - ./jars:/opt/airflow/jars
#       - ./archivePostgres:/opt/airflow
#     networks:
#       - default

#   mongo:
#     container_name: mongo
#     image: nayacollege/mongo:1.0
#     ports:
#       - "27017:27017"
#     networks:
#       - default

#   nifi:
#     container_name: nifi
#     image: nayacollege/nifi:1.0
#     ports:
#       - "8080:8080"
#     networks:
#       - default

#   elasticsearch:
#     container_name: elasticsearch
#     image: docker.elastic.co/elasticsearch/elasticsearch:7.13.2
#     ports:
#       - "9200:9200"
#     environment:
#       discovery.type: single-node
#     networks:
#       - default

#   kibana:
#     container_name: kibana
#     image: docker.elastic.co/kibana/kibana:7.13.2
#     ports:
#       - "5601:5601"
#     depends_on:
#       - elasticsearch
#     networks:
#       - default

#   postgres:
#     container_name: postgres
#     image: postgres:12
#     ports:
#       - "5432:5432"
#     environment:
#       - POSTGRES_USER=postgres
#       - POSTGRES_PASSWORD=postgres
#       - POSTGRES_DB=airflow
#       - POSTGRES_PORT=5432
#     networks:
#       - default

#   airflow-init:
#     image: apache/airflow:2.0.0
#     container_name: airflow_init
#     environment:
#       - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
#       - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
#       - AIRFLOW__CORE__LOAD_EXAMPLES=False
#       - AIRFLOW__CORE__LOGGING_LEVEL=INFO
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./airflow-data/logs:/opt/airflow/logs
#       - ./airflow-data/plugins:/opt/airflow/plugins
#       - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
#     depends_on:
#       - postgres
#     entrypoint: /bin/bash
#     command:
#       - -c
#       - >
#         airflow users list || (
#         airflow db init &&
#         airflow users create
#         --role Admin
#         --username airflow
#         --password airflow
#         --email airflow@airflow.com
#         --firstname airflow
#         --lastname airflow )
#     restart: on-failure
#     networks:
#       - default

#   airflow-webserver:
#     image: apache/airflow:2.0.0
#     container_name: airflow_webserver
#     environment:
#       - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
#       - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
#       - AIRFLOW__CORE__LOAD_EXAMPLES=False
#       - AIRFLOW__CORE__LOGGING_LEVEL=INFO
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./airflow-data/logs:/opt/airflow/logs
#       - ./airflow-data/plugins:/opt/airflow/plugins
#       - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
#     command: airflow webserver
#     ports:
#       - "8082:8080"
#     depends_on:
#       - postgres
#     restart: always
#     networks:
#       - default

#   airflow-scheduler:
#     image: apache/airflow:2.0.0
#     container_name: airflow_scheduler
#     environment:
#       - AIRFLOW__CORE__EXECUTOR=LocalExecutor
#       - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
#       - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
#       - AIRFLOW__CORE__LOAD_EXAMPLES=False
#       - AIRFLOW__CORE__LOGGING_LEVEL=INFO
#     volumes:
#       - ./dags:/opt/airflow/dags
#       - ./airflow-data/logs:/opt/airflow/logs
#       - ./airflow-data/plugins:/opt/airflow/plugins
#       - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
#     depends_on:
#       - postgres
#     command: airflow scheduler
#     restart: always
#     networks:
#       - default

#   trino:
#     container_name: trino
#     image: ofrir119/trino:420
#     ports:
#       - "8080:8080"
#     depends_on:
#       - hive-metastore
#     networks:
#       - default

# networks:
#   default:
#     name: final_project_network